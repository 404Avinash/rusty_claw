# AI Lawyer â€” Complete Project Explainer

> **Stack:** Python Â· FastAPI Â· Rich TUI Â· ArmorIQ SDK Â· Google Gemini (optional)  
> **Repo:** https://github.com/404Avinash/rusty_claw  
> **Event:** ArmorIQ Ã— OpenClaw Hackathon  

---

## Table of Contents

1. [What This Project Is](#1-what-this-project-is)
2. [High-Level Architecture](#2-high-level-architecture)
3. [Folder Structure](#3-folder-structure)
4. [Entry Points](#4-entry-points)
5. [Core Layer â€” The Brain & Enforcement](#5-core-layer)
   - [intent_model.py](#51-intent_modelpy)
   - [llm_brain.py](#52-llm_brainpy)
   - [policy_engine.py](#53-policy_enginepy)
   - [executor.py](#54-executorpy)
   - [csrg.py](#55-csrgpy)
   - [injection_detector.py](#56-injection_detectorpy)
   - [audit_logger.py](#57-audit_loggerpy)
6. [Agents Layer](#6-agents-layer)
   - [lead_lawyer.py](#61-lead_lawyerpy)
   - [research_agent.py](#62-research_agentpy)
7. [Tools Layer](#7-tools-layer)
8. [Memory Layer](#8-memory-layer)
9. [Policies â€” legal_rules.json](#9-policies--legal_rulesjson)
10. [Web UI & API Server](#10-web-ui--api-server)
11. [ArmorIQ SDK Integration â€” Deep Dive](#11-armoriq-sdk-integration--deep-dive)
12. [Request Lifecycle â€” Step by Step](#12-request-lifecycle--step-by-step)
13. [Security Architecture](#13-security-architecture)
14. [Environment Variables](#14-environment-variables)
15. [Running Locally](#15-running-locally)
16. [Demo Scenes (main.py)](#16-demo-scenes-mainpy)

---

## 1. What This Project Is

**AI Lawyer** is an agentic legal assistant that can analyse a client's case, build a legal strategy, draft documents, search case law, and advise the client â€” all while being **cryptographically prevented from doing anything unethical or illegal**.

The key innovation is that every action the AI wants to take must pass **two enforcement layers** before it executes:

| Layer | What it does |
|---|---|
| **Local Policy Engine** | Checks `policies/legal_rules.json` â€” hard-coded ethical/legal rules (no perjury, no Rule 4.2 violation, no fabrication) |
| **ArmorIQ SDK (CSRG)** | Cryptographically signs the plan *before* execution; verifies every action at runtime against a Merkle-proof chain |

If either layer says **NO**, the action is hard-blocked. No exceptions.

---

## 2. High-Level Architecture

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚           CLIENT / USER                â”‚
                         â”‚  (web/index.html  or  main.py CLI)     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚ HTTP / CLI
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚           server.py (FastAPI)           â”‚
                         â”‚  POST /analyze   GET /case/:id          â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚         agents/lead_lawyer.py           â”‚
                         â”‚  1. intake_case()                       â”‚
                         â”‚  2. analyze_and_act()                   â”‚
                         â”‚     â”œâ”€ llm_brain.generate_plan()   â”€â”€â”€â”€ â–º ArmorIQ IAP
                         â”‚     â”‚      returns (plan, mode, token)  â”‚  capture_plan()
                         â”‚     â””â”€ For each IntentObject:           â”‚  get_intent_token()
                         â”‚         â”œâ”€ policy_engine.validate()     â”‚
                         â”‚         â””â”€ executor.execute()      â”€â”€â”€â”€ â–º Merkle proof check
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                             â”‚                          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  core/policy_engine â”‚    â”‚   core/executor.py   â”‚    â”‚   core/csrg.py     â”‚
   â”‚  â€¢ Load rules JSON  â”‚    â”‚  â€¢ Run tool if ALLOW â”‚    â”‚  â€¢ Merkle chain    â”‚
   â”‚  â€¢ Time constraints â”‚    â”‚  â€¢ ArmorIQ step proofâ”‚    â”‚  â€¢ CSRG hash nodes â”‚
   â”‚  â€¢ ArmorIQ SDK verifyâ”‚   â”‚  â€¢ Drift detection   â”‚    â”‚                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ tools/legal_tools   â”‚    â”‚  memory/case_store   â”‚    â”‚  audit_logger      â”‚
   â”‚  â€¢ summarize_case   â”‚    â”‚  â€¢ JSON case files   â”‚    â”‚  â€¢ JSONL audit log â”‚
   â”‚  â€¢ search_case_law  â”‚    â”‚  â€¢ load/save/update  â”‚    â”‚  â€¢ every decision  â”‚
   â”‚  â€¢ draft_document   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚  â€¢ advise_client    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Folder Structure

```
claw/
â”œâ”€â”€ main.py                  # Rich CLI demo (5 scenes)
â”œâ”€â”€ server.py                # FastAPI REST + WebSocket server
â”œâ”€â”€ build_ui.py              # Utility to serve / build UI assets
â”œâ”€â”€ requirements.txt         # Python deps (FastAPI, armoriq-sdk, rich, â€¦)
â”œâ”€â”€ .env                     # ğŸ”’ Secret keys (gitignored)
â”œâ”€â”€ .env.example             # Template for environment variables
â”œâ”€â”€ Procfile                 # Render.com deploy config
â”œâ”€â”€ render.yaml              # Render.com service config
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ lead_lawyer.py       # Top-level orchestrating agent
â”‚   â””â”€â”€ research_agent.py    # Sub-agent (delegated, scoped)
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ intent_model.py      # IntentObject dataclass + enums
â”‚   â”œâ”€â”€ llm_brain.py         # LLM reasoning + ArmorIQ plan registration
â”‚   â”œâ”€â”€ policy_engine.py     # Rule enforcement + ArmorIQ token verify
â”‚   â”œâ”€â”€ executor.py          # Tool execution + Merkle proof enforcement
â”‚   â”œâ”€â”€ csrg.py              # Local CSRG Merkle tree implementation
â”‚   â”œâ”€â”€ injection_detector.py# Prompt injection scanner
â”‚   â””â”€â”€ audit_logger.py      # Append-only JSONL audit log
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ legal_tools.py       # All callable legal tools (TOOL_REGISTRY)
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ case_store.py        # Case load/save (JSON files in cases/)
â”‚   â””â”€â”€ cases/
â”‚       â””â”€â”€ CASE-2026-001.json
â”‚
â”œâ”€â”€ policies/
â”‚   â””â”€â”€ legal_rules.json     # Declarative rule set (YAML-like JSON)
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ audit_log.jsonl      # Append-only decision log
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ *.txt                # Generated legal documents
â”‚
â””â”€â”€ web/
    â”œâ”€â”€ index.html           # Single-page React-like UI (Tailwind + vanilla JS)
    â””â”€â”€ static/              # Static assets
```

---

## 4. Entry Points

### `main.py` â€” CLI Demo
The fastest way to see everything. Runs **5 scripted scenes** in a Rich terminal UI:
1. Client intake
2. Allowed legal actions (summarise, search law, draft, advise)
3. Perjury attempt â†’ BLOCKED
4. Rule 4.2 violation (direct opposing contact) â†’ BLOCKED
5. Delegation enforcement (research agent scope check)

```bash
python main.py
```

### `server.py` â€” REST API Backend
FastAPI app that powers the web UI:
- `POST /analyze` â€” receives case query, runs full pipeline, returns JSON results
- `GET /case/{case_id}` â€” fetch stored case data
- Static file serving for `web/`

```bash
uvicorn server:app --reload --port 8000
```

---

## 5. Core Layer

### 5.1 `intent_model.py`

Defines the **IntentObject** â€” the universal unit of work. Every action the AI wants to take is expressed as an `IntentObject` before it touches any tool.

```python
@dataclass
class IntentObject:
    action: str           # e.g. "draft_document"
    initiated_by: str     # e.g. "lead_lawyer"
    target: str           # e.g. "client_letter"
    content: str          # what to do / write
    case_id: str          # CASE-2026-001
    delegated_by: str     # set when a sub-agent acts (e.g. "lead_lawyer")
    timestamp: str        # ISO 8601
```

`ACTION_LABELS` maps action names to human-readable descriptions:
```python
ACTION_LABELS = {
    "summarize_case":   "Summarise Case File",
    "search_case_law":  "Search Case Law",
    "draft_document":   "Draft Legal Document",
    "advise_client":    "Advise Client",
    "file_motion":      "File Court Motion",
    ...
}
```

`PolicyDecision` is the return type from the policy engine â€” `ALLOWED` or `BLOCKED`.

---

### 5.2 `llm_brain.py`

The **reasoning layer** â€” decides *what actions to take* for a given case query.

**Priority cascade:**
1. **Gemini API** (if `GEMINI_API_KEY` set) â†’ real LLM reasoning, JSON output
2. **Simulation fallback** (no key) â†’ keyword-matched intents

**ArmorIQ integration happens here** â€” immediately after plan generation:

```
generate_plan(case_data, query)
    â”‚
    â”œâ”€ [Gemini / simulation] â†’ list of IntentObjects
    â”‚
    â””â”€ _register_plan_with_armoriq(prompt, plan_items, ...)
           â”‚
           â”œâ”€ client.capture_plan(llm=..., prompt=..., plan={goal, steps})
           â”‚        â†‘ sends plan to ArmorIQ backend for audit
           â”‚
           â””â”€ client.get_intent_token(plan_capture_id)
                    â†‘ returns signed IntentToken with:
                      â€¢ plan_hash (SHA-256 of plan)
                      â€¢ step_proofs (one Merkle proof per step)
                      â€¢ signed_by (Ed25519 public key)
                      â€¢ expires_at
```

**Return signature:**
```python
def generate_plan(case_data, query) -> tuple[list[dict], str, IntentToken | None]:
    #                                          plan_items  mode   armoriq_token
```

The token is threaded through to every `IntentObject` so the executor can verify each step.

---

### 5.3 `policy_engine.py`

The **local enforcement layer** â€” authoritative, fail-closed, runs before any tool executes.

**What it checks (in order):**

1. **Injection scan** â€” calls `injection_detector.scan()`, blocks prompt injection
2. **Delegation scope** â€” if `delegated_by` is set, checks the sub-agent only uses allowed actions
3. **Time constraints** â€” some rules only apply in business hours (IST), court filing windows, etc.
4. **Block list** â€” actions explicitly blocked (e.g. `fabricate_evidence`, `perjury`, `contact_opposing_party`)
5. **Allow list** â€” only whitelisted actions can execute
6. **ArmorIQ SDK verify** â€” cryptographically confirms the intent token is valid

**ArmorIQ verification path:**
```python
def _verify_with_armoriq_sdk(intent, session_token=None):
    if session_token and not session_token.is_expired:
        verified = client.verify_token(session_token)
        return verified, token.plan_hash[:32], "sdk"
    else:
        # issue a single-action token for standalone calls
        plan_capture = client.capture_plan(...)
        token = client.get_intent_token(...)
        return True, token.plan_hash[:32], "sdk"
```

**Decision metadata returned:**
```json
{
  "decision": "ALLOWED",
  "enforcement_type": "SOFT_LOG | HARD_BLOCK",
  "reason": "...",
  "rule_violated": "...",
  "intent_token": "abc123...",
  "sdk_mode": "sdk | local",
  "csrg_hash": "...",
  "merkle_root": "..."
}
```

---

### 5.4 `executor.py`

The **execution layer** â€” runs the approved tool and applies Merkle proof enforcement afterwards.

**Execution flow:**
```
execute(intent, policy_result)
    â”‚
    â”œâ”€ if decision == BLOCKED â†’ raise PolicyViolationError immediately
    â”‚
    â”œâ”€ _invoke_via_armoriq(intent, tool_result)
    â”‚       â”‚
    â”‚       â”œâ”€ Check token not expired
    â”‚       â”œâ”€ client.verify_token(token) â€” cryptographic check
    â”‚       â”œâ”€ Check intent.action âˆˆ token.step_proofs (intent drift detection)
    â”‚       â”‚       â””â”€ If NOT present â†’ raise PolicyViolationError("armoriq_intent_drift")
    â”‚       â””â”€ Log Merkle proof hash per step
    â”‚
    â”œâ”€ TOOL_REGISTRY[intent.action](intent) â€” actually calls the tool function
    â”‚
    â””â”€ return {
           "decision": "ALLOWED",
           "result": tool_output,
           "armoriq_enforced": True,
           "armoriq_verified": True,
           "token_id": "...",
           "plan_hash": "...",
           "step_index": 0,
           "merkle_proof_present": True,
       }
```

**Intent Drift Detection** is the crown jewel: if the AI tries to execute an action that was NOT in the original signed plan (e.g. plan said "search_case_law" but at runtime it tries "file_motion"), the Merkle proof won't match â†’ hard block with `rule_violated="armoriq_intent_drift"`.

---

### 5.5 `csrg.py`

Local **CSRG Merkle tree** implementation â€” Cryptographic State-Result Graph.

Every policy decision is hashed and appended to a chain:
```
node_0 = sha256("genesis")
node_1 = sha256(node_0 + decision_1_json)
node_2 = sha256(node_1 + decision_2_json)
...
```

This means the full decision history is tamper-evident. Any modification to a past decision will break the chain. The Merkle root is included in every policy response.

Used for:
- Tamper-evident audit trails
- Court-admissible decision provenance
- The ArmorIQ CSRG badge in the UI

---

### 5.6 `injection_detector.py`

Scans every `IntentObject.content` for prompt injection patterns before the policy engine checks rules:

- Regex patterns for classic injection strings (`ignore previous instructions`, `jailbreak`, etc.)
- Action injection: attempts to inject a new action keyword into the content
- Returns `(is_injection: bool, injection_type: str, confidence: float)`

If injection is detected â†’ immediate `HARD_BLOCK` with `enforcement_type="INJECTION"`, the action never reaches the policy rules.

---

### 5.7 `audit_logger.py`

Append-only JSONL log at `logs/audit_log.jsonl`.

Every `PolicyDecision` is serialised and appended with:
```json
{
  "timestamp": "2026-02-26T10:23:45.123Z",
  "agent": "lead_lawyer",
  "delegated_by": null,
  "proposed_action": "draft_document",
  "target": "demand_notice",
  "case_id": "CASE-2026-001",
  "status": "ALLOWED",
  "enforcement_type": null,
  "rule_violated": null,
  "reason": "Action is on the allowed list",
  "intent_token": "a3f9...",
  "sdk_mode": "sdk",
  "merkle_root": "8f2c..."
}
```

Since it is append-only (file opened in `"a"` mode), no entry can be deleted or modified after the fact.

---

## 6. Agents Layer

### 6.1 `lead_lawyer.py`

The **top-level orchestrating agent**. It is the only agent that talks directly to the LLM Brain.

**Key methods:**

```python
lawyer.intake_case(statement: str, case_id: str)
    # Stores client statement in CaseStore
    # Returns case dict

lawyer.analyze_and_act(case_id: str, query: str) -> list[dict]
    # 1. Load case from CaseStore
    # 2. Call LLMBrain.generate_plan() â†’ (plan_items, mode, armoriq_token)
    # 3. Register simulation plans with ArmorIQ too (simulation fallback path)
    # 4. For each plan item:
    #    a. Build IntentObject
    #    b. Attach armoriq_token via setattr(intent, '_armoriq_token', token)
    #    c. Run policy_engine.validate(intent, session_token=token)
    #    d. Run executor.execute(intent, policy_result)
    #    e. Collect result dict (includes armoriq_enforced, verified, token_id, plan_hash)
    # 5. Return list of result dicts

lawyer.spawn_research_agent(case_id: str) -> ResearchAgent
    # Creates a sub-agent with a restricted action scope
    # Delegation is enforced by the policy engine (delegated_by field)
```

---

### 6.2 `research_agent.py`

A **scoped sub-agent** spawned by the lead lawyer for research tasks only.

- Allowed actions: `search_case_law`, `read_case_files`
- Sets `delegated_by="lead_lawyer"` on every `IntentObject`
- The policy engine checks: if `delegated_by` is set, only actions in the delegation whitelist are permitted
- Attempting `draft_document` or `advise_client` from the research agent â†’ `HARD_BLOCK` with `rule_violated="delegation_scope_exceeded"`

---

## 7. Tools Layer

`tools/legal_tools.py` contains all the callable tool functions. Each function takes an `IntentObject` and returns a string result.

| Tool | What it does |
|---|---|
| `summarize_case` | Reads case file from `memory/cases/`, returns structured summary |
| `search_case_law` | Keyword search against embedded case law dataset, returns precedents |
| `draft_document` | Templates a legal document (demand notice, complaint, etc.) and saves to `output/` |
| `advise_client` | Generates legal advice narrative based on case facts |
| `file_motion` | Prepares court motion document |
| `read_case_files` | Raw case file read (research agent only) |

`TOOL_REGISTRY` is a plain dict mapping action name â†’ function:
```python
TOOL_REGISTRY = {
    "summarize_case":  summarize_case,
    "search_case_law": search_case_law,
    "draft_document":  draft_document,
    "advise_client":   advise_client,
    "file_motion":     file_motion,
    "read_case_files": read_case_files,
}
```

The executor calls `TOOL_REGISTRY[intent.action](intent)`. If the action isn't in the registry, it raises `KeyError` (which is caught and converted to a policy block).

---

## 8. Memory Layer

`memory/case_store.py` â€” simple JSON-file-backed case storage.

```python
store = CaseStore()

# Create / load
case = store.load_case("CASE-2026-001")

# Update
store.update_case("CASE-2026-001", {"status": "active", "facts": [...]})

# Cases stored at:
# memory/cases/CASE-2026-001.json
```

Case JSON structure:
```json
{
  "case_id": "CASE-2026-001",
  "client_statement": "My landlord has been illegally entering...",
  "practice_area": "tenant_rights",
  "status": "active",
  "created_at": "2026-02-26T10:00:00Z",
  "facts": [],
  "documents": [],
  "actions_taken": []
}
```

---

## 9. Policies â€” `legal_rules.json`

The declarative rule set. Loaded at runtime by the policy engine (hot-reloadable without restarting the server).

Structure:
```json
{
  "version": "2.0",
  "jurisdiction": "India",
  "legal_framework": "BNS 2023",
  "allowed_actions": ["summarize_case", "search_case_law", "draft_document", ...],
  "blocked_actions": ["fabricate_evidence", "perjury", "destroy_evidence", ...],
  "delegation_rules": {
    "research_agent": ["search_case_law", "read_case_files"]
  },
  "time_constraints": {
    "file_motion": { "allowed_hours": [9, 17], "timezone": "IST" }
  },
  "rules": [
    {
      "id": "RULE-4.2",
      "name": "no_opposing_party_contact",
      "description": "An agent may not contact a represented opposing party directly",
      "actions_blocked": ["contact_opposing_party", "message_landlord"],
      "enforcement": "HARD_BLOCK",
      "citation": "Bar Council of India Rules, Rule 4.2"
    },
    {
      "id": "RULE-PERJURY",
      "name": "no_perjury",
      "actions_blocked": ["fabricate_statement", "deny_receipt"],
      "enforcement": "HARD_BLOCK",
      "citation": "BNS 2023 Section 227"
    }
  ]
}
```

---

## 10. Web UI & API Server

### `server.py` (FastAPI)

**Endpoints:**

| Method | Path | Description |
|---|---|---|
| `POST` | `/analyze` | Run full pipeline on a query |
| `GET` | `/case/{case_id}` | Get stored case |
| `GET` | `/logs` | Get full audit log |
| `GET` | `/` | Serve web UI |

**Request body for `/analyze`:**
```json
{
  "query": "landlord illegal entry harassment",
  "case_id": "CASE-2026-001"
}
```

**Response for `/analyze`:**
```json
{
  "case_id": "CASE-2026-001",
  "actions": [
    {
      "action": "summarize_case",
      "decision": "ALLOWED",
      "result": "Case summary...",
      "armoriq_enforced": true,
      "armoriq_verified": true,
      "armoriq_token_id": "990d514d...",
      "armoriq_plan_hash": "a3f91c...",
      "sdk_mode": "sdk",
      "merkle_root": "8f2c..."
    }
  ]
}
```

### `web/index.html`

Single-file SPA (no bundler). Uses:
- **Tailwind CSS** (CDN) for styling
- Vanilla JS `fetch()` for API calls
- **Action cards**: one card per action, shows verdict badge, result text, and ArmorIQ CSRG badge

ArmorIQ badge (shown when `armoriq_enforced === true`):
```
ğŸ” ArmorIQ CSRG verified Â· token 990d514d... Â· hash a3f91c...
```

---

## 11. ArmorIQ SDK Integration â€” Deep Dive

### What ArmorIQ Provides

ArmorIQ is a **Cryptographic Intent Guard** for AI agents. It prevents:
- Intent drift (plan says X, runtime does Y)
- Unauthorized action injection
- Unaudited agent behaviour

### SDK Flow

```
1. pip install armoriq-sdk

2. client = ArmorIQClient(
       api_key=...,
       user_id=...,
       agent_id=...,
       context_id="legal-hackathon"
   )

3. plan_capture = client.capture_plan(
       llm="simulation",          # or "gemini-1.5-pro"
       prompt="Handle case...",
       plan={
           "goal": "...",
           "steps": [
               {"action": "summarize_case", "mcp": "ai-lawyer", "params": {...}},
               {"action": "search_case_law", "mcp": "ai-lawyer", "params": {...}},
           ]
       },
       metadata={"case_id": "CASE-2026-001"}
   )

4. intent_token = client.get_intent_token(plan_capture.id)
   # Returns IntentToken with:
   #   .plan_hash       â€” SHA-256 of the full plan
   #   .step_proofs     â€” list of Merkle proof nodes, one per step
   #   .signed_by       â€” Ed25519 public key
   #   .expires_at      â€” token TTL
   #   .is_expired      â€” bool property

5. At execution time, for each action:
   verified = client.verify_token(intent_token)
   # Checks Ed25519 signature + TTL

6. Intent drift check (local, no network call):
   action_in_plan = any(
       proof.action == intent.action
       for proof in intent_token.step_proofs
   )
   if not action_in_plan:
       raise PolicyViolationError("armoriq_intent_drift")
```

### Why NOT using `client.invoke()`?

`client.invoke(mcp="ai-lawyer", ...)` routes through the ArmorIQ proxy, which requires your agent to be registered as an **HTTP MCP server** in the ArmorIQ dashboard. Since this project runs locally (not as a public HTTP endpoint), the proxy returns `400 MCP server not found`.

**The solution**: use **local Merkle proof verification** from `intent_token.step_proofs`. This is cryptographically equivalent â€” the token was signed by ArmorIQ's Ed25519 key, so the proofs can be verified offline.

### Verified Test Output

```
âœ… Stage 1 â€” SDK client initialised
âœ… Stage 2 â€” Intent token issued: 990d514d... (7 Merkle proofs)
âœ… Stage 3 â€” Agent ran: 4 allowed, 0 blocked
   âœ… summarize_case    [sdk]
   âœ… search_case_law   [sdk]
   âœ… draft_document    [sdk]
   âœ… advise_client     [sdk]
âœ… Stage 4 â€” Perjury correctly blocked: INJECTION:ACTION_INJECTION
âœ… Stage 5 â€” Merkle chain: 4 nodes, valid=True
ğŸ‰ Full end-to-end test PASSED with real ArmorIQ key!
```

---

## 12. Request Lifecycle â€” Step by Step

Here is the exact journey of the query `"landlord illegal entry harassment"` for `CASE-2026-001`:

```
POST /analyze  {"query": "landlord illegal entry harassment", "case_id": "CASE-2026-001"}
  â”‚
  â–¼
server.py â†’ lawyer.analyze_and_act("CASE-2026-001", "landlord illegal entry harassment")
  â”‚
  â–¼
llm_brain.generate_plan(case_data, query)
  â”œâ”€ [No Gemini key] â†’ simulation: keyword "landlord" + "entry" â†’ 4 intents
  â”‚    summarize_case, search_case_law, draft_document, advise_client
  â””â”€ _register_plan_with_armoriq(prompt, plan_items, ...)
       â”œâ”€ capture_plan() â†’ plan_capture_id = "abc..."
       â””â”€ get_intent_token("abc...") â†’ IntentToken (4 step_proofs, signed)
  
Returns: ([4 intents], "simulation", IntentToken)
  â”‚
  â–¼
For each intent (e.g. "summarize_case"):
  1. Build IntentObject(action="summarize_case", initiated_by="lead_lawyer", ...)
  2. setattr(intent, '_armoriq_token', intent_token)
  3. injection_detector.scan(intent) â†’ clean
  4. policy_engine.validate(intent, session_token=intent_token)
       â”œâ”€ "summarize_case" NOT in blocked_actions âœ…
       â”œâ”€ "summarize_case" IN allowed_actions âœ…
       â”œâ”€ No time constraints âœ…
       â”œâ”€ client.verify_token(intent_token) â†’ True âœ…
       â””â”€ Returns PolicyDecision.ALLOWED + metadata
  5. executor.execute(intent, policy_result)
       â”œâ”€ _invoke_via_armoriq(intent, ...):
       â”‚    â”œâ”€ verify_token() â†’ True âœ…
       â”‚    â””â”€ "summarize_case" IN step_proofs â†’ no drift âœ…
       â”œâ”€ TOOL_REGISTRY["summarize_case"](intent) â†’ "Case Summary: ..."
       â””â”€ audit_logger.log_decision(ALLOWED, ...)
  6. Result: {decision:"ALLOWED", result:"Case Summary:...", armoriq_enforced:true, ...}
  â”‚
  â–¼
server.py serializes â†’ JSON response with all 4 action results
  â”‚
  â–¼
web/index.html renders action cards with ğŸ” ArmorIQ badges
```

---

## 13. Security Architecture

### Layered Defense Model

```
Request
   â”‚
   â–¼ Layer 0 â”€â”€â”€ InjectionDetector â”€â”€â”€â”€ blocks prompt injection
   â”‚
   â–¼ Layer 1 â”€â”€â”€ PolicyEngine (local) â”€â”€ blocks unethical/illegal actions
   â”‚                                      (perjury, fabrication, Rule 4.2)
   â”‚
   â–¼ Layer 2 â”€â”€â”€ ArmorIQ SDK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ cryptographic intent token verify
   â”‚                                      (Ed25519 + Merkle proof)
   â”‚
   â–¼ Layer 3 â”€â”€â”€ Executor (drift check) â”€ ensures runtime action == signed plan
   â”‚                                       (intent drift detection)
   â”‚
   â–¼ Layer 4 â”€â”€â”€ CSRG Merkle chain â”€â”€â”€â”€â”€â”€ tamper-evident audit trail
   â”‚
Tool executed âœ…
```

### Fail-Closed Design

- If ArmorIQ SDK is unavailable â†’ falls back to **local token** (SHA-256), but still enforces all local rules
- If LLM returns invalid JSON â†’ simulation fallback, plan still registered with ArmorIQ
- If Merkle proof missing for a step â†’ `merkle_proof_present: False` in result (logged, not blocked â€” the ArmorIQ `verify_token` already confirmed the overall signature)
- If token expired â†’ `PolicyViolationError` immediately, action blocked

### What CANNOT Happen (by design)

| Attack | Blocked by |
|---|---|
| Prompt injection into content | InjectionDetector (Layer 0) |
| Ask AI to commit perjury | PolicyEngine rule RULE-PERJURY (Layer 1) |
| Contact opposing party directly | PolicyEngine rule RULE-4.2 (Layer 1) |
| Research agent tries to draft documents | Delegation scope check (Layer 1) |
| Plan registered then different action runs | Intent drift detection (Layer 3) |
| Replay old token | `is_expired` check (Layer 2) |
| Tamper with audit log retroactively | CSRG Merkle chain (Layer 4) |

---

## 14. Environment Variables

| Variable | Required | Description |
|---|---|---|
| `ARMORIQ_API_KEY` | âœ… Yes | ArmorIQ live API key (`ak_live_...`) |
| `ARMORIQ_USER_ID` | Optional | User identifier (default: `ai-lawyer-user`) |
| `ARMORIQ_AGENT_ID` | Optional | Agent identifier (default: `ai-lawyer-agent`) |
| `GEMINI_API_KEY` | Optional | Google Gemini key for real LLM reasoning |

Without `GEMINI_API_KEY` the system runs in **simulation mode** (keyword-matched plans). All ArmorIQ enforcement still works identically â€” the plan is registered and signed regardless of whether it came from Gemini or simulation.

```env
# .env (gitignored)
ARMORIQ_API_KEY=ak_live_...
ARMORIQ_USER_ID=avinash1807007
ARMORIQ_AGENT_ID=ai-lawyer-agent
GEMINI_API_KEY=          # optional
```

---

## 15. Running Locally

```bash
# 1. Clone
git clone https://github.com/404Avinash/rusty_claw.git
cd rusty_claw

# 2. Create virtualenv
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # Linux/Mac

# 3. Install deps
pip install -r requirements.txt

# 4. Configure env
cp .env.example .env
# Edit .env: add ARMORIQ_API_KEY

# 5a. Run CLI demo (5 scenes, no browser needed)
python main.py

# 5b. Run web server
uvicorn server:app --reload --port 8000
# Open http://127.0.0.1:8000
```

---

## 16. Demo Scenes (`main.py`)

The CLI runs 5 structured scenes to showcase every feature:

| Scene | What happens | ArmorIQ outcome |
|---|---|---|
| **1 â€” Case Intake** | Client describes landlord illegal entry. Case stored in `memory/cases/`. | Plan registered, token issued |
| **2 â€” Allowed Actions** | AI builds strategy: summarise â†’ search law â†’ draft notice â†’ advise. All 4 execute. | `[sdk]` badge, Merkle proofs verified |
| **3 â€” Perjury Attempt** | Client asks AI to lie about receiving a notice. Blocked before it reaches a tool. | `INJECTION:ACTION_INJECTION` â†’ `HARD_BLOCK` |
| **4 â€” Rule 4.2** | Client asks to contact landlord directly. Blocked by Bar Council Rule 4.2. | `HARD_BLOCK`, `rule_violated: "RULE-4.2"` |
| **5 â€” Delegation** | Lead lawyer spawns research agent. Research agent tries to draft â€” blocked. Then does search â€” allowed. | Delegation scope enforced |

After all scenes, a full audit table is printed showing every decision with timestamps, agents, rules, and Merkle roots.

---

*Generated: 2026-02-26 | Commit: 105cf2e | Built for ArmorIQ Ã— OpenClaw Hackathon*
